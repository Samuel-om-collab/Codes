{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Installing Dependencies**"
      ],
      "metadata": {
        "id": "zy58yrslxdfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Installs **Dask** (a parallel computing framework) with all optional dependencies.\n",
        "\n",
        "\n",
        "*   Installs **Dask-ML**, an extension of Dask for scalable machine learning.\n",
        "\n",
        "\n",
        "*   --quiet suppresses output messages\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MTwurKUCxwBE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHneZEowkMpD",
        "outputId": "3a3e530e-0a26-498a-a3d7-c661bdd97cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.8/149.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install dask[complete] dask-ml --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Importing Required Libraries**"
      ],
      "metadata": {
        "id": "UC3u6m91y_Q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **dask.dataframe:** Works like Pandas but handles large datasets efficiently.\n",
        "\n",
        "\n",
        "*   **dask.array:** Similar to NumPy but operates on chunks of data in parallel.\n",
        "\n",
        "*   **Client**: Manages Dask’s distributed execution.\n",
        "*   **pandas and numpy**: Used for creating initial data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fs3VtMob0XnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "from dask.distributed import Client\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "ho0F0h45lKmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Initializing a Dask Client**"
      ],
      "metadata": {
        "id": "8KpdgBAt1G5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Initializes a **Dask Client** in single-machine mode.\n",
        "*   Allows better monitoring and parallel processing.\n",
        "\n",
        "*   Prints the client details, such as the number of workers and available resources.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nXu7FZT61N9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Dask Client(Single Machine Mode)\n",
        "client = Client()\n",
        "print(client)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7k2F7zo02Fn",
        "outputId": "9dfabbdd-3e68-4a83-b24c-677d835592af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
            "Perhaps you already have a cluster running?\n",
            "Hosting the HTTP server on port 42633 instead\n",
            "  warnings.warn(\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:34465\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:42633/status\n",
            "INFO:distributed.scheduler:Registering Worker plugin shuffle\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:33651'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:33125'\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:43053 name: 0\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:43053\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:42940\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:46057 name: 1\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:46057\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:42944\n",
            "INFO:distributed.scheduler:Receive client connection: Client-32839700-0aea-11f0-855f-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:42946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Client: 'tcp://127.0.0.1:34465' processes=2 threads=2, memory=12.67 GiB>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Creating a Large Pandas DataFrame**"
      ],
      "metadata": {
        "id": "Fz7m80kE14sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " Simulates a big dataset with:\n",
        "*   id: Unique identifiers (0 to 999,999).\n",
        "\n",
        "\n",
        "\n",
        "*   value: Random numbers between 1 and 99.\n",
        "\n",
        "\n",
        "*   category: Randomly assigned categories (\"A\", \"B\", or \"C\").\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QZYwypWD2IYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a large pandas dataframe (simulating big data)\n",
        "n_rows = 1_000_000 # 1 million rows\n",
        "df = pd.DataFrame({\n",
        "    \"id\": np.arange(n_rows),\n",
        "    \"value\": np.random.randint(1, 100, n_rows),\n",
        "    \"category\": np.random.choice([\"A\",\"B\",\"C\"],n_rows)\n",
        "})\n",
        "\n"
      ],
      "metadata": {
        "id": "q0ysORmdlysF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Converting Pandas DataFrame to Dask DataFrame**"
      ],
      "metadata": {
        "id": "RW5Fm9t72wo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Converts the large Pandas DataFrame into a **Dask DataFrame.**\n",
        "*   **Partitions** allow parallel computation (here, into 10 parts).\n",
        "\n"
      ],
      "metadata": {
        "id": "WO1DPP1Q27s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert pandas dataframe to dask datatrame\n",
        "ddf = dd.from_pandas(df,npartitions=10) #split into 10 partitions"
      ],
      "metadata": {
        "id": "b_Xlg0E52EXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Exploring the Dask DataFrame**"
      ],
      "metadata": {
        "id": "PMt-r2gZ3X_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  ** head()**: Fetches a small part of the data (triggers computation).\n",
        "\n",
        "\n",
        "*   **dtypes**: Shows column types (metadata only, no computation).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fZM7rrGd3kTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the first few rows(lazy execution)\n",
        "print(ddf.head())\n",
        "\n",
        "#Get data types(metadata only,doesn't load full data)\n",
        "print(ddf.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbs17AxTntUD",
        "outputId": "44f09344-fe08-4803-8f5f-8ca191c46bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  value category\n",
            "0   0     94        A\n",
            "1   1     44        A\n",
            "2   2     59        C\n",
            "3   3     60        C\n",
            "4   4     91        C\n",
            "id                    int64\n",
            "value                 int64\n",
            "category    string[pyarrow]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Filtering** Data (Lazy Execution)\n",
        "python\n",
        "\n",
        "*   Filters rows where value > 50.\n",
        "*   Lazy Execution: Dask only records this operation but doesn't execute it yet.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BC1lIGPX4RIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. **Aggregation (Lazy Execution)**\n",
        "\n",
        "*   Groups by category and computes the mean of value.\n",
        "*   Again, execution is **deferred** until .compute() is called.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U3T3tOkC67XI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9**. Computing Results (Trigger Execution)**\n",
        "\n",
        "*   **.compute() **forces execution and converts the **Dask** **DataFrame** back into Pandas.\n",
        "*  **head()**: Fetches first few rows after filtering.\n",
        "\n",
        "*  **compute()** on grouped_ddf: Performs the aggregation.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lnFpOapP77ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the first rows (lazy execution)\n",
        "print(ddf.head())\n",
        "\n",
        "#Get data types(metadata only,doesn't load full data)\n",
        "print(ddf.dtypes)\n",
        "\n",
        "#Perform filtering (lazy execution)\n",
        "filtered_ddf = ddf[ddf[\"value\"] >50]\n",
        "\n",
        "#Perform Aggregations (lazy execution)\n",
        "grouped_ddf = ddf.groupby(\"category\")[\"value\"].mean()\n",
        "\n",
        "#Compute results(Trigger execution)\n",
        "print(filtered_ddf.compute().head()) #convert to pandas for viewing\n",
        "print(grouped_ddf.compute()) #perform actual aggregation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OSe06ncohzK",
        "outputId": "948b99fd-8f81-4b5c-c6eb-7047a324551e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  value category\n",
            "0   0     94        A\n",
            "1   1     44        A\n",
            "2   2     59        C\n",
            "3   3     60        C\n",
            "4   4     91        C\n",
            "id                    int64\n",
            "value                 int64\n",
            "category    string[pyarrow]\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.85 MiB.\n",
            "This may cause some slowdown.\n",
            "Consider loading the data with Dask directly\n",
            " or using futures or delayed objects to embed the data into the graph without repetition.\n",
            "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  value category\n",
            "0   0     94        A\n",
            "2   2     59        C\n",
            "3   3     60        C\n",
            "4   4     91        C\n",
            "5   5     56        B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 16.22 MiB.\n",
            "This may cause some slowdown.\n",
            "Consider loading the data with Dask directly\n",
            " or using futures or delayed objects to embed the data into the graph without repetition.\n",
            "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category\n",
            "A    49.944410\n",
            "B    50.036332\n",
            "C    50.108784\n",
            "Name: value, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **10. Creating a Large Dask Array python**\n",
        "\n",
        "*  Creates a **Dask Array** with **10 million** random numbers (between 0 and 1).\n",
        "*   Uses **chunks** of 1 million for parallel processing.\n",
        "\n"
      ],
      "metadata": {
        "id": "-qA-Zm5W8rKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **11. Computing Mean & Sum (Lazy Until .compute() is Called)**\n",
        "\n",
        "*  ** .mean():** Computes the mean value (lazy until .compute() is called).\n",
        "\n",
        "\n",
        "*   **.sum():** Computes the sum.\n",
        "\n",
        "*   **.compute(): **Triggers actual calculation.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dTcWpUg19L-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a large dask array (10 million elements,chunked)\n",
        "arr = da.random.random(size=(10_000_000,), chunks=(1_000_000,))\n",
        "\n",
        "# compute mean and sum (lazy until '.compute()' is called)\n",
        "mean_value = arr.mean().compute()\n",
        "sum_value = arr.sum().compute()\n",
        "\n",
        "print(\"Mean:\", mean_value)\n",
        "print(\"Sum:\", sum_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMw6AT2NqTgs",
        "outputId": "e09835e1-8670-4f66-ee45-e3e661ba0145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 0.5001505350535234\n",
            "Sum: 5001505.3505352335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **12. Training a Linear Regression Model with Dask-ML**\n",
        "\n",
        "*   **Imports Dask-ML’s** LinearRegression, which works on large datasets in parallel.\n",
        "\n"
      ],
      "metadata": {
        "id": "a-NIEuhI91ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  .Generates synthetic data for regression (10,000 rows, 2 features).\n",
        "\n",
        "  .Splits into chunks of 1,000 for efficient parallel processing"
      ],
      "metadata": {
        "id": "ERqtS0YJ-L55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " .Initializes and trains a linear regression model using Dask-ML.\n",
        "\n",
        " .Unlike Scikit-learn, this can scale better with large datasets.\n"
      ],
      "metadata": {
        "id": "pgQ1FPiP-c6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Makes predictions.**\n",
        "\n",
        "**.compute()** converts lazy predictions into a NumPy array.\n",
        "\n",
        "**[:5] prints** the first five predicted values."
      ],
      "metadata": {
        "id": "rkQLaqjz-oe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dask_ml.linear_model import LinearRegression\n",
        "\n",
        "# Create a synthetic dataset\n",
        "X = da.random.random((10_000,2), chunks=(1_000,2))\n",
        "y = da.random.random(10_000, chunks=(1_000,))\n",
        "\n",
        "# Train a scalable Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "#Predict values\n",
        "predictions = model.predict(X)\n",
        "print(predictions.compute()[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Qpjre4tn-T",
        "outputId": "43ed9c93-8115-44e6-9600-d0abd0317582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.50064557 0.50399265 0.5004294  0.49909728 0.50151214]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **13. Closing the Dask Client**\n",
        "\n",
        "*   Shuts down the Dask Client to free resources.\n",
        "\n"
      ],
      "metadata": {
        "id": "MZag1Vq6-v5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zhGbjpDvZTI",
        "outputId": "38e7eb4e-6a99-4fce-ebd0-370974bec410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:Remove client Client-79fe885d-0ae0-11f0-855f-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33822; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-79fe885d-0ae0-11f0-855f-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-79fe885d-0ae0-11f0-855f-0242ac1c000c\n",
            "INFO:distributed.scheduler:Retire worker addresses (stimulus_id='retire-workers-1743064522.4764302') (0, 1)\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:38997'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:34217'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33802; closing.\n",
            "INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:36021 name: 1 (stimulus_id='handle-worker-cleanup-1743064522.4915686')\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33804; closing.\n",
            "INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:39373 name: 0 (stimulus_id='handle-worker-cleanup-1743064522.498598')\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:34217' closed.\n",
            "INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:38997' closed.\n",
            "INFO:distributed.scheduler:Closing scheduler. Reason: unknown\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ]
    }
  ]
}